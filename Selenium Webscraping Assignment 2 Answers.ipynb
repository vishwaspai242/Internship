{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcebd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing Selenium Library\n",
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d30fd",
   "metadata": {},
   "source": [
    "# Question 1 Answer ---> python program to scrape data for “Data Analyst” Job position in “Bangalore” location. Scraping First 10 job-title, job-location, company_name, experience_required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee328a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver    # importing webdriver module from selenium to open up automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ignoring warnings that might arise\n",
    "import time                       # used to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593253ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca42d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9639fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job search bar and entering in Skill, Designations, Companies field\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deffd915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering location Bangalore in location search bar\n",
    "search_field_location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_field_location.send_keys(\"Bangalore\")  # since bangalore gets inputed in location we have to use absolute full xpath to get the location search section since there are 2 suggestor-input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882353e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search button clicking\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a6da144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty lists for the data we have to extract and store in them\n",
    "job_titles=[]\n",
    "job_locations=[]\n",
    "company_names=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e80c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job titles\n",
    "titles_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:10]  # using range to print only top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the text of the job title is inside the tags extracted above\n",
    "# we will run a loop to iterate over the tags extracted above and extract the text inside\n",
    "\n",
    "for i in titles_tags:          # iterating over each web element of title_tags\n",
    "    title=i.text               # extracting text from web element\n",
    "    job_titles.append(title)   # appending each text into empty list\n",
    "job_titles[0:10]               # using range to print only top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dbbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the location tags\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "location_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting location names from location_tags\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    job_locations.append(location)\n",
    "job_locations[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the companies tags\n",
    "companies_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting company names from companies_tags\n",
    "for i in companies_tags:\n",
    "    company_name=i.text                  \n",
    "    company_names.append(company_name)  \n",
    "company_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the tags having the experience required data\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "experience_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting experience required data from experience_tags\n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "experience_required[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing length off all lists\n",
    "print(len(job_titles),len(job_locations),len(company_names),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258cb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe which contains the top 20 details from page 1 extracted from above steps\n",
    "dataanalystjobs=pd.DataFrame({})\n",
    "dataanalystjobs['Job Titles']=job_titles\n",
    "dataanalystjobs['Job Locations']=job_locations\n",
    "dataanalystjobs['Company Names']=company_names\n",
    "dataanalystjobs['Experience Required']=experience_required\n",
    "\n",
    "dataanalystjobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "973abcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Job Locations</th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Analyst II</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business and Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CAREERDOST ENTERPRISE</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Capco</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Jayanagar)</td>\n",
       "      <td>G S E-COMMERCE PVT LTD</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Python / SQL</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reference Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Analyst with SAP ABAP &amp; BW - C...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MILLION MINDS INFOTECH PRIVATE LIMITED</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAS Analyst / data Analyst / Business analyst ...</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Leading US MNC into analytics</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst 2-1</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Titles  \\\n",
       "0                                 Sr Data Analyst II   \n",
       "1                          Business and Data Analyst   \n",
       "2                                Senior Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                        Data Analyst - Python / SQL   \n",
       "5                             Reference Data Analyst   \n",
       "6  Hiring For Data Analyst with SAP ABAP & BW - C...   \n",
       "7  SAS Analyst / data Analyst / Business analyst ...   \n",
       "8                                   Data Analyst 2-1   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                       Job Locations  \\\n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...   \n",
       "3                     Bangalore/Bengaluru(Jayanagar)   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                            Company Names Experience Required  \n",
       "0                              IHS Markit             3-6 Yrs  \n",
       "1                   CAREERDOST ENTERPRISE             0-5 Yrs  \n",
       "2                                   Capco            7-12 Yrs  \n",
       "3                  G S E-COMMERCE PVT LTD             4-7 Yrs  \n",
       "4                                  Myntra             1-4 Yrs  \n",
       "5                           Deutsche Bank             2-5 Yrs  \n",
       "6  MILLION MINDS INFOTECH PRIVATE LIMITED            7-10 Yrs  \n",
       "7           Leading US MNC into analytics             2-7 Yrs  \n",
       "8                                  PayPal             5-8 Yrs  \n",
       "9                                  PayPal             1-3 Yrs  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataanalystjobsfirst10 = dataanalystjobs.iloc[0:10]\n",
    "dataanalystjobsfirst10        #filtering only first 10 job results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5ebbf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()  # to close the driver at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c50a37",
   "metadata": {},
   "source": [
    "# Question 2 Answer --> python program to scrape data for “Data Scientist” Job position in “Bangalore” location. Scraping first 10 jobs data which contains the job-title, job-location, company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c573e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver    # importing webdriver module from selenium to open up automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ignoring warnings that might arise\n",
    "import time                       # used to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb39554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc0fb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04bb14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job search bar and entering in Skill, Designations, Companies field\n",
    "designation = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca9c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering location Bangalore in location search bar\n",
    "location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "location.send_keys(\"Bangalore\")  # since bangalore gets inputed in location we have to use absolute full xpath to get the location search section since there are 2 suggestor-input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927677af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search button clicking\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f702910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty lists for the data we have to extract and store in them\n",
    "job_titles2=[]\n",
    "job_locations2=[]\n",
    "company_names2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82857da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job titles\n",
    "titles_tags2 = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags2[0:10]  # using range to print only top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the text of the job title is inside the tags extracted above\n",
    "# we will run a loop to iterate over the tags extracted above and extract the text inside\n",
    "\n",
    "for i in titles_tags2:          # iterating over each web element of title_tags\n",
    "    title=i.text                # extracting text from web element\n",
    "    job_titles2.append(title)   # appending each text into empty list\n",
    "job_titles2[0:10]               # using range to print only top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the location tags\n",
    "location_tags2=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "location_tags2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33021177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting location names from location_tags\n",
    "for i in location_tags2:\n",
    "    location=i.text\n",
    "    job_locations2.append(location)\n",
    "job_locations2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de90cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the companies tags\n",
    "companies_tags2 = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbaf32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting company names from companies_tags\n",
    "for i in companies_tags2:\n",
    "    company_name=i.text                  \n",
    "    company_names2.append(company_name)  \n",
    "company_names2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f658062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "#printing length off all lists\n",
    "print(len(job_titles2),len(job_locations2),len(company_names2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe which contains the top 20 details from page 1 extracted from above steps\n",
    "datascientistjobs=pd.DataFrame({})\n",
    "datascientistjobs['Job Titles']=job_titles2\n",
    "datascientistjobs['Job Locations']=job_locations2\n",
    "datascientistjobs['Company Names']=company_names2\n",
    "\n",
    "datascientistjobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d401f99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Job Locations</th>\n",
       "      <th>Company Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rolls-Royce Data Labs : Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Rolls Royce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist 1</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayPal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Opportunity with PayU - Diversi...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cognitive/AI Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assistant Manager/Manager/Senior Manager - Dat...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Titles  \\\n",
       "0             Rolls-Royce Data Labs : Data Scientist   \n",
       "1            Data Scientist: Artificial Intelligence   \n",
       "2                               Staff Data Scientist   \n",
       "3                                  Sr Data Scientist   \n",
       "4                                   Data Scientist 1   \n",
       "5  Data Scientist Opportunity with PayU - Diversi...   \n",
       "6                                Lead Data Scientist   \n",
       "7                              Senior Data Scientist   \n",
       "8                 Cognitive/AI Senior Data Scientist   \n",
       "9  Assistant Manager/Manager/Senior Manager - Dat...   \n",
       "\n",
       "                                       Job Locations  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "               Company Names  \n",
       "0                Rolls Royce  \n",
       "1                        IBM  \n",
       "2                    Walmart  \n",
       "3                     Target  \n",
       "4                     PayPal  \n",
       "5                       PayU  \n",
       "6                     Target  \n",
       "7                    Walmart  \n",
       "8                        IBM  \n",
       "9  Huquo Consulting Pvt. Ltd  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datascientistjobsfirst10 = datascientistjobs.iloc[0:10]\n",
    "datascientistjobsfirst10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3619061",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()  # to close the driver at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d81ef",
   "metadata": {},
   "source": [
    "# Question 3 Answer ---> scrape data for “Data Scientist” designation for first 10 job results, data such as job-title, job-location, company name, experience required, with location filter as “Delhi/NCR” and salary filter as “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3ff8af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver     # importing webdriver module from selenium to open up automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # ignoring warnings that might arise\n",
    "import time                        # used to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8a419de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53a57152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0809d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job search bar and entering in Skill, Designations, Companies field\n",
    "designation3 = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "designation3.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6774c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search button clicking\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "682edb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location filter to be used is “Delhi/NCR”.\n",
    "location_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[3]/label/i\")\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c21bf754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The salary filter to be used is “3-6” lakhs\n",
    "salary_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[1]/div[2]/div[2]/label/i\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eedefa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty lists for the data we have to extract and store in them\n",
    "job_titles3=[]\n",
    "job_locations3=[]\n",
    "company_names3=[]\n",
    "experience_required3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job titles\n",
    "titles_tags3 = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags3[0:10]  # using range to print only top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea713615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the text of the job title is inside the tags extracted above\n",
    "# we will run a loop to iterate over the tags extracted above and extract the text inside\n",
    "\n",
    "for i in titles_tags3:          # iterating over each web element of title_tags\n",
    "    title=i.text                # extracting text from web element\n",
    "    job_titles3.append(title)   # appending each text into empty list\n",
    "job_titles3[0:10]               # using range to print only top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58408f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the location tags\n",
    "location_tags3=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "location_tags3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac61ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting location names from location_tags\n",
    "for i in location_tags3:\n",
    "    location=i.text\n",
    "    job_locations3.append(location)\n",
    "job_locations3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the companies tags\n",
    "companies_tags3 = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting company names from companies_tags\n",
    "for i in companies_tags3:\n",
    "    company_name=i.text                  \n",
    "    company_names3.append(company_name)  \n",
    "company_names3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the tags having the experience required data\n",
    "experience_tags3=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "experience_tags3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb66b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting experience required data from experience_tags\n",
    "for i in experience_tags3:\n",
    "    experience=i.text\n",
    "    experience_required3.append(experience)\n",
    "experience_required3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3a6134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "#printing length off all lists\n",
    "print(len(job_titles3),len(job_locations3),len(company_names3),len(experience_required3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe which contains the top 20 details from page 1 extracted from above steps\n",
    "datascientistjobs3=pd.DataFrame({})\n",
    "datascientistjobs3['Job Titles']=job_titles3\n",
    "datascientistjobs3['Job Locations']=job_locations3\n",
    "datascientistjobs3['Company Names']=company_names3\n",
    "datascientistjobs3['Experience Required']=experience_required3\n",
    "\n",
    "datascientistjobs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "151523af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Job Locations</th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Scientist - Data Engineering</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AXA Technology Services India Pvt. Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist/ Machine Learning, 2022 Passout...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Delhi /...</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Analyst and Data Scientist For...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Shadow Placements</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Python/SQL</td>\n",
       "      <td>Noida, Kota, Mumbai, Chandigarh, Lucknow, Agra...</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Titles  \\\n",
       "0                                     Data Scientist   \n",
       "1                           Associate Data Scientist   \n",
       "2             Associate Scientist - Data Engineering   \n",
       "3                                     Data Scientist   \n",
       "4                         Data Scientist (freelance)   \n",
       "5  Data Scientist/ Machine Learning, 2022 Passout...   \n",
       "6  Hiring For Data Analyst and Data Scientist For...   \n",
       "7                        Data Scientist - Python/SQL   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                       Job Locations  \\\n",
       "0                         Noida, Bangalore/Bengaluru   \n",
       "1                                   Gurgaon/Gurugram   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3                                 Gurgaon, Bengaluru   \n",
       "4                                   New Delhi, Delhi   \n",
       "5  Hyderabad/Secunderabad, Pune, Chennai, Delhi /...   \n",
       "6               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "7  Noida, Kota, Mumbai, Chandigarh, Lucknow, Agra...   \n",
       "8  Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...   \n",
       "9                                          New Delhi   \n",
       "\n",
       "                            Company Names Experience Required  \n",
       "0      Ashkom Media India Private Limited             3-6 Yrs  \n",
       "1                                   Optum             1-5 Yrs  \n",
       "2  AXA Technology Services India Pvt. Ltd             2-5 Yrs  \n",
       "3                               BlackBuck             3-7 Yrs  \n",
       "4                                   2Coms             2-7 Yrs  \n",
       "5           Creative Hands HR Consultancy             0-4 Yrs  \n",
       "6                       Shadow Placements             3-7 Yrs  \n",
       "7                            AVE-Promagne             3-8 Yrs  \n",
       "8                          Country Veggie             1-3 Yrs  \n",
       "9                 Boston Consulting Group             2-5 Yrs  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datascientistjobs3first10 = datascientistjobs3.iloc[0:10]\n",
    "datascientistjobs3first10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a8db702",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()  # to close the driver at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa9acf",
   "metadata": {},
   "source": [
    "# Question 4 Answer ---> Scraping data of first 100 sunglasses listings on flipkart.com scraping four attributes: 1. Brand 2. Product Description 3. Price. The attributes to scrape is ticked marked in the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "49cc9ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver     # importing webdriver module from selenium to open up automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # ignoring warnings that might arise\n",
    "import time                        # used to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "02edee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4ac2d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up flipkart.com website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "627f3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing the pop up for login sign\n",
    "closing_login_popup = driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button\")\n",
    "closing_login_popup.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e462f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “sunglasses” in the search field where “search for products, brands and more” is written\n",
    "product_name = driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "product_name.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f461e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search icon\n",
    "search_icon = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6160d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since in the question its not mentioned to scrap each pages individually we will not use the loop method\n",
    "#creating empty lists to store the data\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing brand data from first page, 1-40 items\n",
    "brand1 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand1[0:4]   #printing 4 tag data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f8429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting brand name data from the brand tags from first page, 1-40 items\n",
    "for i in brand1:\n",
    "    brandname=i.text\n",
    "    brand.append(brandname)\n",
    "brand[0:4]   #printing 4 brand names just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d99d72b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand)  # 40 items data appended into the brand list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing product description from first page, 1-40 items\n",
    "productdesc1 = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "productdesc1[0:4]   # printing 4 tag data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c1d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting product description data from the product description tags from first page, 1-40 items\n",
    "for i in productdesc1:\n",
    "    product=i.text\n",
    "    product_description.append(product)\n",
    "product_description[0:4]   #printing 4 product description just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "26701bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_description) # 40 items data appended into the product_description list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing price data from first page, 1-40 items\n",
    "price1 = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price1[0:4]   # printing 4 tag data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting price data from the price tags from first page, 1-40 items\n",
    "for i in price1:\n",
    "    pricetext=i.text\n",
    "    price.append(pricetext)\n",
    "price[0:4]   # printing 4 prices just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6e6a9dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing discount % data from first page, 1-40 items\n",
    "discount1 = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "discount1[0:4]   # printing 4 discount % data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7965c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting discount % data from the price tags from first page, 1-40 items\n",
    "for i in discount1:\n",
    "    discounttext=i.text\n",
    "    discount.append(discounttext)\n",
    "discount[0:4]   # printing 4 discount % just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1a13d80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "911caa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# “Next” Button at the bottom ofthe page , then clicking on it.\n",
    "next_button=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing brand data from second page, 41-80 items\n",
    "brand2 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand2[0:4]   #printing 4 tag data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38728420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting brand name data from the brand tags from second page, 41-80 items\n",
    "for i in brand2:\n",
    "    brandname=i.text\n",
    "    brand.append(brandname)\n",
    "brand[40:44]   #printing 40-44 brand names just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c04fc3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand) # 40 items added to the previous 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb80418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing product description from second page, 41-80 items\n",
    "productdesc2 = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "productdesc2[0:4]   # printing 4 tag data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting product description data from the product description tags from second page, 41-80 items\n",
    "for i in productdesc2:\n",
    "    product=i.text\n",
    "    product_description.append(product)\n",
    "product_description[40:44]   #printing 4 product description just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8f81b9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_description) # 40 items added to the previous 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724fd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing price data from second page, 41-80 items\n",
    "price2 = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price2[0:4]   # printing 4 tag data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eea067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting price data from the price tags from second page, 41-80 items\n",
    "for i in price2:\n",
    "    pricetext=i.text\n",
    "    price.append(pricetext)\n",
    "price[40:44]   # printing 4 prices just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b0c48282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(price) # 40 items added to the previous 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing discount % data from second page, 41-80 items\n",
    "discount2 = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "discount2[0:4]   # printing 4 discount % data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ea75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting discount % data from the price tags from second page, 41-80 items\n",
    "for i in discount2:\n",
    "    discounttext=i.text\n",
    "    discount.append(discounttext)\n",
    "discount[40:44]   # printing 4 discount % just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "33deb34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(discount) # 40 items added to the previous 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ef744d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# “Next” Button at the bottom ofthe page , then clicking on it.\n",
    "next_button=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7877f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing brand data from third page, 81-120 items\n",
    "brand3 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand3[0:4]   #printing 4 tag data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23146006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting brand name data from the brand tags from third page, 81-120 items\n",
    "for i in brand3:\n",
    "    brandname=i.text\n",
    "    brand.append(brandname)\n",
    "brand[80:84]   #printing 40-44 brand names just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9e27e837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand) # 40 items added to the previous 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a948a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing product description from third page, 81-120 items\n",
    "productdesc3 = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "productdesc3[0:4]   # printing 4 tag data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting product description data from the product description tags from third page, 81-120 items\n",
    "for i in productdesc3:\n",
    "    product=i.text\n",
    "    product_description.append(product)\n",
    "product_description[80:84]   #printing 4 product description just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "da03b303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_description) # 40 items added to the previous 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing price data from third page, 81-120 items\n",
    "price3 = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price3[0:4]   # printing 4 tag data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting price data from the price tags from third page, 81-120 items\n",
    "for i in price3:\n",
    "    pricetext=i.text\n",
    "    price.append(pricetext)\n",
    "price[80:84]   # printing 4 prices just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9294d8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(price) # 40 items added to the previous 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tags containing discount % data from third page, 81-120 items\n",
    "discount3 = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "discount3[0:4]   # printing 4 discount % data just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47c1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting discount % data from the price tags from third page, 81-120 items\n",
    "for i in discount3:\n",
    "    discounttext=i.text\n",
    "    discount.append(discounttext)\n",
    "discount[80:84]   # printing 4 discount % just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "396820bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(discount) # 40 items added to the previous 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9d6daa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "#printing length off all lists\n",
    "print(len(brand),len(product_description),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data frame which has 120 items information extracted by the steps above\n",
    "flipkartsunglassesdata = pd.DataFrame({'Brand Name':brand,'Product Description':product_description,'Price':price,'Discount':discount})\n",
    "flipkartsunglassesdata      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "edabed04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹283</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi</td>\n",
       "      <td>Polarized Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>HIPPON</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹207</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹269</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Cat-eye, Oval Sunglass...</td>\n",
       "      <td>₹498</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹225</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹719</td>\n",
       "      <td>10% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                Product Description Price  \\\n",
       "0         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹719   \n",
       "1           SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...  ₹283   \n",
       "2         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹639   \n",
       "3        Elligator                UV Protection Round Sunglasses (54)  ₹295   \n",
       "4               Mi           Polarized Aviator Sunglasses (Free Size)  ₹799   \n",
       "..             ...                                                ...   ...   \n",
       "95          HIPPON             UV Protection Wayfarer Sunglasses (55)  ₹207   \n",
       "96  kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹269   \n",
       "97          AISLIN  UV Protection, Gradient Cat-eye, Oval Sunglass...  ₹498   \n",
       "98          PIRASO              UV Protection Aviator Sunglasses (54)  ₹225   \n",
       "99        Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹719   \n",
       "\n",
       "   Discount  \n",
       "0   20% off  \n",
       "1   78% off  \n",
       "2   20% off  \n",
       "3   88% off  \n",
       "4   33% off  \n",
       "..      ...  \n",
       "95  82% off  \n",
       "96  82% off  \n",
       "97  70% off  \n",
       "98  85% off  \n",
       "99  10% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering them into first 100 sunglasses information as per the answer request\n",
    "sunglassesdatafirst100 = flipkartsunglassesdata.iloc[0:100,:]\n",
    "sunglassesdatafirst100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "515e2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()   # to close the driver at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d1d89",
   "metadata": {},
   "source": [
    "# Question 5 Answer ---> scarping first 100 reviews data from flipkart.com for iphone11 phone. The data to be scraped are Rating, Review summary, Full review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ded6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the link from the pdf for iphone 11 reviews was not opening (screen shot attached in the messages) \n",
    "# we took the liberty to manually search the flipkart site for the exact same page of reviews and used that link to scrap the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b811467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the link referred\n",
    "# https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&q=apple+iphone+11+black&store=tyy%2F4io&srno=s_1_6&otracker=search&otracker1=search&fm=Search&iid=1981aea3-1ac4-40e3-a39d-360493424af5.MOBFKCTSVZAXUHGR.SEARCH&ppt=sp&ppn=sp&ssid=ztmg8jnm9c0000001652099555656&qH=463388d252f4d3d7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bbcbd6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver     # importing webdriver module from selenium to open up automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # ignoring warnings that might arise\n",
    "import time                        # used to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b692f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b38174da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up flipkart link provided on automated chrome window\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYL0BETT&marketplace=FLIPKART&sattr[]=color&sattr[]=storage&st=storage&otracker=search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f46b0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we need first 100 reviews we have to click on \"All 6047 reviews\" to get all the reviews opened\n",
    "reviews = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[6]/div/a/div\")\n",
    "reviews.click()                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "200efa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=[]\n",
    "review_summary=[]    \n",
    "full_review=[]                 #creating empty list to store title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "71192924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the absolute x path changes after the first page and then remains the same \n",
    "#we choose to run this loop once and run the remaining 9 pages in another loop\n",
    "for i in range(0,1):            # running for loop with range to run this loop once\n",
    "    rating_tags=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq' or @class='_3LWZlK _1rdVr6 _1BLPMq']\")   # locating web element of rating_tags for both green and red colourd ratings which have different classes, hence or operation is used\n",
    "    for i in rating_tags:        # iterating over each web element of rating_tags\n",
    "        rating=i.text            # fetching text from the web element\n",
    "        ratings.append(rating)   # appending ratings (text) into the empty list\n",
    "    reviews_tags=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")      # locating reviews summary tags\n",
    "    for i in reviews_tags:\n",
    "        review=i.text\n",
    "        review_summary.append(review)                                        # appending text to review_summary list\n",
    "    fullreview_tags=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")     # locating reviews full review tags\n",
    "    for i in fullreview_tags:\n",
    "        fullreview=i.text\n",
    "        full_review.append(fullreview)                                       #appending text to full_review list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]\")   # first page next button\n",
    "    next_button.click()           # locating web element of next button and then clicking on next button\n",
    "    time.sleep(5)                 # using time to pause the search engine for 5 sec between each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "74361b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ef5964a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the absolute x path changes after the first page and then remains the same \n",
    "# we choose to run this loop of 1 to 10 and run the remaining 9 pages in this loop\n",
    "for i in range(1,10):            # running for loop with range to run this loop once\n",
    "    rating_tags=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq' or @class='_3LWZlK _1rdVr6 _1BLPMq']\")   # locating web element of rating_tags for both green and red colourd ratings which have different classes, hence or operation is used\n",
    "    for i in rating_tags:        # iterating over each web element of rating_tags\n",
    "        rating=i.text            # fetching text from the web element\n",
    "        ratings.append(rating)   # appending ratings (text) into the empty list\n",
    "    reviews_tags=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")      # locating reviews summary tags\n",
    "    for i in reviews_tags:\n",
    "        review=i.text\n",
    "        review_summary.append(review)                                        # appending text to review_summary list\n",
    "    fullreview_tags=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")   # locating reviews full review tags\n",
    "    for i in fullreview_tags:\n",
    "        fullreview=i.text\n",
    "        full_review.append(fullreview)                                       # appending text to full_review list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")   # consecutive pages next button\n",
    "    next_button.click()           # locating web element of next button and then clicking on next button\n",
    "    time.sleep(6)                 # using time to pause the search engine for 6 sec between each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "27ef4c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "51239fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Did an upgrade from 6s plus to iphone 11.\\nAo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Gifted my man on his 30th birthday 🎂 He loves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Here is the thing\\n\\nThe only reason why you s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>It was amazing experience for me. Honestly i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>If you are looking for a premium phone under 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings       Review Summary  \\\n",
       "0        5            Brilliant   \n",
       "1        5       Simply awesome   \n",
       "2        5  Best in the market!   \n",
       "3        5     Perfect product!   \n",
       "4        5            Fabulous!   \n",
       "..     ...                  ...   \n",
       "95       5               Super!   \n",
       "96       5       Classy product   \n",
       "97       5    Worth every penny   \n",
       "98       5            Excellent   \n",
       "99       4         Nice product   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Did an upgrade from 6s plus to iphone 11.\\nAo ...  \n",
       "96  Gifted my man on his 30th birthday 🎂 He loves ...  \n",
       "97  Here is the thing\\n\\nThe only reason why you s...  \n",
       "98  It was amazing experience for me. Honestly i a...  \n",
       "99  If you are looking for a premium phone under 5...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame which has 100 items information extracted by the steps above\n",
    "iphonereviews = pd.DataFrame({'Ratings':ratings,'Review Summary':review_summary,'Full Review':full_review})\n",
    "iphonereviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c3ec0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() # for closing the driver at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e44f6",
   "metadata": {},
   "source": [
    "# Question 6 Answer ---> scraping first 100 sneakers from flipkart.com, 4 attributes of each sneaker: Brand, Product Description, Price and discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f43eb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver     # importing webdriver module from selenium to open up automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # ignoring warnings that might arise\n",
    "import time                        # used to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "635bebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f69f991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up flipkart.com website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7db31b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing the pop up for login sign\n",
    "closing_login_popup = driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button\")\n",
    "closing_login_popup.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4f67c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “sneakers” in the search field where “search for products, brands and more” is written\n",
    "product_name6 = driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "product_name6.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3698c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search icon\n",
    "search_icon = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0dc21bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists to store the data\n",
    "brand6=[]\n",
    "product_description6=[]\n",
    "price6=[]\n",
    "discount6=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a0ee670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since in the question its not mentioned to scrap each pages individually we will use the loop method\n",
    "# since the absolute x path changes after the first page and then remains the same for the consecutive pages\n",
    "# we choose to run this loop once and run the remaining 2 pages in another loop to get a total of 120 datas and then filter it to first 100\n",
    "for i in range(0,1):            # running for loop with range to run this loop once\n",
    "    brand_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")   # locating web element of brand tags\n",
    "    for i in brand_tags:         # iterating over each web element of brand_tags\n",
    "        brand=i.text             # fetching text from the web element\n",
    "        brand6.append(brand)     # appending brand (text) into the empty list\n",
    "    product_description_tags=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")   # locating product_description_tags\n",
    "    for i in product_description_tags:\n",
    "        product=i.text\n",
    "        product_description6.append(product)                              # appending text to product_description6 list\n",
    "    price_tags=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")    # locating reviews price tags\n",
    "    for i in price_tags:\n",
    "        price=i.text\n",
    "        price6.append(price)                                    #appending text to price6 list\n",
    "    discount_tags=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")    # locating reviews discount tags\n",
    "    for i in discount_tags:\n",
    "        discount=i.text\n",
    "        discount6.append(discount)                                    #appending text to discount6 list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")  # first page next button\n",
    "    next_button.click()           # locating web element of next button and then clicking on next button\n",
    "    time.sleep(5)                 # using time to pause the search engine for 5 sec between each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "792a63a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 40\n"
     ]
    }
   ],
   "source": [
    "# printing length\n",
    "print(len(brand6),len(product_description6),len(price6),len(discount6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8951c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the remaining 2 pages in another loop to get a total of 120 datas and then filter it to first 100\n",
    "for i in range(1,3):            # running for loop with range to run this loop twice\n",
    "    brand_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")   # locating web element of brand tags\n",
    "    for i in brand_tags:         # iterating over each web element of brand_tags\n",
    "        brand=i.text             # fetching text from the web element\n",
    "        brand6.append(brand)     # appending brand (text) into the empty list\n",
    "    product_description_tags=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")   # locating product_description_tags\n",
    "    for i in product_description_tags:\n",
    "        product=i.text\n",
    "        product_description6.append(product)                              # appending text to product_description6 list\n",
    "    price_tags=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")    # locating reviews price tags\n",
    "    for i in price_tags:\n",
    "        price=i.text\n",
    "        price6.append(price)                                    #appending text to price6 list\n",
    "    discount_tags=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")    # locating reviews discount tags\n",
    "    for i in discount_tags:\n",
    "        discount=i.text\n",
    "        discount6.append(discount)                                    #appending text to discount6 list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\")  # second and third page next button\n",
    "    next_button.click()           # locating web element of next button and then clicking on next button\n",
    "    time.sleep(5)                 # using time to pause the search engine for 5 sec between each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1c963e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "# printing length\n",
    "print(len(brand6),len(product_description6),len(price6),len(discount6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a84a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data frame which has 120 items information extracted by the steps above\n",
    "sneakerreviews = pd.DataFrame({'Brand Name':brand6,'Product Description':product_description6,'Price':price6,'Discount':discount6})\n",
    "sneakerreviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ffc0fd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Navtrend</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Navtrend</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹429</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹148</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Canvas shoes for Men Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>casual for men Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>casual for men Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>STRANGER BROTHERS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹384</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>EZDEZARIO</td>\n",
       "      <td>Shoes in Black Color Party wear/Outdoor/Casual...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand Name                                Product Description  \\\n",
       "0            Navtrend                                   Sneakers For Men   \n",
       "1            Navtrend                                   Sneakers For Men   \n",
       "2            URBANBOX                          Sneakers Sneakers For Men   \n",
       "3              BRUTON              Canvas shoes for Men Sneakers For Men   \n",
       "4              Labbin                                   Sneakers For Men   \n",
       "..                ...                                                ...   \n",
       "95          bluemaker                    casual for men Sneakers For Men   \n",
       "96          bluemaker                    casual for men Sneakers For Men   \n",
       "97             Layasa                                   Sneakers For Men   \n",
       "98  STRANGER BROTHERS                                   Sneakers For Men   \n",
       "99          EZDEZARIO  Shoes in Black Color Party wear/Outdoor/Casual...   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹449  77% off  \n",
       "1   ₹429  78% off  \n",
       "2   ₹148  85% off  \n",
       "3   ₹299  76% off  \n",
       "4   ₹449  55% off  \n",
       "..   ...      ...  \n",
       "95  ₹449  55% off  \n",
       "96  ₹449  55% off  \n",
       "97  ₹449  55% off  \n",
       "98  ₹384  61% off  \n",
       "99  ₹349  65% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakerreviewsfirst100 = sneakerreviews.iloc[0:100,:]   # filtering to first 100 sneakers data\n",
    "sneakerreviewsfirst100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2625475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() # for closing the driver at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55270218",
   "metadata": {},
   "source": [
    "# Question 7 Answer ---> Scraping first 100 shoes data from https://www.myntra.com/shoes and setting Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black” data includes “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ac22cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver     # importing webdriver module from selenium to open up automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # ignoring warnings that might arise\n",
    "import time                        # used to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7f81d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1690628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up https://www.myntra.com/shoes website on automated chrome window\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9919dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting Color filter as “Black”\n",
    "color_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "82834b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since “Rs. 7149 to Rs. 14099” is not there in the page we selected Rs. 7119 to Rs. 14079(882)\n",
    "price_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "299f6150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists to store the data\n",
    "brand7=[]\n",
    "short_shoe_description=[]\n",
    "price7=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b41626f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since in the question its not mentioned to scrap each pages individually we will use the loop method\n",
    "# we run this loop twice to get a total of 100 data of the shoes since each page contains 50 data\n",
    "# Since the loop is skipping to the 10th page for some reason we ran the loop twice\n",
    "for i in range(0,1):            # running loop once\n",
    "    brand_tags=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")   # locating web element of brand tags\n",
    "    for i in brand_tags:         # iterating over each web element of brand_tags\n",
    "        brand=i.text             # fetching text from the web element\n",
    "        brand7.append(brand)     # appending brand (text) into the empty list\n",
    "    shoe_description_tags=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")   # locating shoe_description_tags\n",
    "    for i in shoe_description_tags:\n",
    "        shoe=i.text\n",
    "        short_shoe_description.append(shoe)                              # appending text to short_shoe_description list\n",
    "    price_tags=driver.find_elements_by_xpath(\"//div[@class='product-price']\")    # locating reviews price tags\n",
    "    for i in price_tags:\n",
    "        price=i.text\n",
    "        price7.append(price)                                    #appending text to price7 list                                    #appending text to discount6 list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a\")  # first page next button\n",
    "    next_button.click()           # locating web element of next button and then clicking on next button\n",
    "    time.sleep(5)                 # using time to pause the search engine for 5 sec between each page\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f951d771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "# printing length\n",
    "print(len(brand7),len(short_shoe_description),len(price7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0137e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we run this loop twice to get a total of 100 data of the shoes since each page contains 50 data\n",
    "# Since the loop is skipping to the 10th page for some reason we ran the loop twice to get 50 each time\n",
    "for i in range(1,2):            # running loop second time\n",
    "    brand_tags=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")   # locating web element of brand tags\n",
    "    for i in brand_tags:         # iterating over each web element of brand_tags\n",
    "        brand=i.text             # fetching text from the web element\n",
    "        brand7.append(brand)     # appending brand (text) into the empty list\n",
    "    shoe_description_tags=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")   # locating shoe_description_tags\n",
    "    for i in shoe_description_tags:\n",
    "        shoe=i.text\n",
    "        short_shoe_description.append(shoe)                              # appending text to short_shoe_description list\n",
    "    price_tags=driver.find_elements_by_xpath(\"//div[@class='product-price']\")    # locating reviews price tags\n",
    "    for i in price_tags:\n",
    "        price=i.text\n",
    "        price7.append(price)                                    #appending text to price7 list                                    #appending text to discount6 list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[13]/a\")  # first page next button\n",
    "    next_button.click()           # locating web element of next button and then clicking on next button\n",
    "    time.sleep(5)                 # using time to pause the search engine for 5 sec between each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8c9b3dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "# printing length  # 50 in page 2 added to the previous 50 datas\n",
    "print(len(brand7),len(short_shoe_description),len(price7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "aecd8348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand of the Shoes</th>\n",
       "      <th>Short Shoe Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Vantage 2 Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Woven Design Sneakers</td>\n",
       "      <td>Rs. 13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Textured Slip-On Sneakers</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>Rs. 7649Rs. 8999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA Hoops</td>\n",
       "      <td>Men Basketball Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Textured Leather Formal Loafers</td>\n",
       "      <td>Rs. 13990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>Women Trekking Shoes</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand of the Shoes               Short Shoe Description  \\\n",
       "0                   ALDO            Men Leather Driving Shoes   \n",
       "1           UNDER ARMOUR          Men Vantage 2 Running Shoes   \n",
       "2                   ALDO            Men Woven Design Sneakers   \n",
       "3                   ALDO        Men Textured Slip-On Sneakers   \n",
       "4               Skechers           Men Max Cushioning Running   \n",
       "..                   ...                                  ...   \n",
       "95            PUMA Hoops                 Men Basketball Shoes   \n",
       "96  Heel & Buckle London  Men Textured Leather Formal Loafers   \n",
       "97               Bugatti                    Men Walking Shoes   \n",
       "98               Bugatti      Men Solid Leather Formal Derbys   \n",
       "99              Columbia                 Women Trekking Shoes   \n",
       "\n",
       "                        Price  \n",
       "0                   Rs. 12999  \n",
       "1                    Rs. 7999  \n",
       "2                   Rs. 13999  \n",
       "3                   Rs. 12999  \n",
       "4   Rs. 7649Rs. 8999(15% OFF)  \n",
       "..                        ...  \n",
       "95                   Rs. 7999  \n",
       "96                  Rs. 13990  \n",
       "97                   Rs. 8999  \n",
       "98                   Rs. 9499  \n",
       "99                   Rs. 8999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame which has 100 items information extracted by the steps above\n",
    "myntrashoedata = pd.DataFrame({'Brand of the Shoes':brand7,'Short Shoe Description':short_shoe_description,'Price':price7})\n",
    "myntrashoedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()  # to close the driver at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df303b",
   "metadata": {},
   "source": [
    "# Question 8 Answer ---> https://www.amazon.in/ ,  “Laptop” in the search field , CPU Type filter to “Intel Core i7” and “Intel Core i9” , scraping first 10 laptops data, attributed to be scrapped are Title, Ratings and Price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05ec809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver     # importing webdriver module from selenium to open up automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # ignoring warnings that might arise\n",
    "import time                        # used to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00bbbd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "249fc537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up https://www.amazon.in/ website on automated chrome window\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5430a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Laptop” in the search field\n",
    "search_field = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search_field.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8fd26ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search icon\n",
    "click_button = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "click_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9e55da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticked individually cause both i9 and i7 couldnt be ticked together cause of the nature of the filtering doesnt allow it\n",
    "# ticking filter of \"Intel Core i9\"  i9 is selected first cause afterwards in cpu filter only i7 option shows up and i9 doesnt show\n",
    "cpu_filteri9 = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[13]/span/a/div/label/i\")\n",
    "cpu_filteri9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5dc6fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists to store data\n",
    "titlei9=[]\n",
    "ratingsi9=[]\n",
    "pricei9=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating title tags\n",
    "title_tagsi9 = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")  \n",
    "title_tagsi9[0:4]       # printing first 4 title tags just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bfbca99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acer Predator Helios 300 11th Gen Intel Core i9-11900H 15.6\" (39.62cms) FHD IPS Gaming Laptop (16 GB/1TB SSD/Win 11 Home/6 GB Graphics/NVIDIA GeForce RTX 3060/360 Hz, Black, 2.3 kg) PH315-54',\n",
       " 'Acer Predator Helios 300 11th Gen Intel Core i9-11900H 15.6\" (39.62cms) FHD IPS Gaming Laptop (16 GB/1TB SSD/Win 11 Home/6 GB Graphics/NVIDIA GeForce RTX 3060/360 Hz, Black, 2.3 kg) PH315-54',\n",
       " 'ASUS ROG Zephyrus M16 (2022), 16-inch (40.64 cms) 2K QHD 165Hz/3ms, Core i9-12900H 12th Gen, RTX 3080 Ti 16GB Graphics, Gaming Laptop (32GB/2TB SSD/Win 11/Office 2021/Black/2 Kg), GU603ZX-K8024WS',\n",
       " 'HP Envy 15- 11th Gen Intel Core i9/32GB/1TB SSD/15.6 inch(39.6 cm) 400 nits,4K AMOLED Touch, TUV + Win 11 Pro 64/NVIDIA GeForce RTX 3060 6GB Graphics/Alexa/FPR /B&O/2.14kg,15-ep1087TX, Natural Silver',\n",
       " 'Predator Helios 500 Gaming Laptop (11th Gen Intel Core I9/17.3\" 4K UHD Display/64GB DDR4 RAM/2TB SSD/1TB HDD/RTX 3080 Graphics/Per Key RGB Backlit Keyboard) | PH517-52',\n",
       " 'ASUS ROG Strix Scar 15 (2022), 15.6\" (39.62 cms) 2K WQHD 240Hz/3ms, Intel Core i9-12900H 12th Gen, RTX 3070 Ti 8GB Graphics, Gaming Laptop (32GB/1TB SSD/Win 11/Office 2021/Black/2.3 kg) G533ZW-LN136WS',\n",
       " 'ASUS ROG Strix Scar 15 (2022), 15.6-inch (39.62 cms) 2K WQHD 240Hz/3ms, Core i9-12900H 12th Gen, RTX 3070 Ti 8GB Graphics, Gaming Laptop (32GB/2TB SSD/Win 11/Office 2021/Black/2.3 Kg), G533ZW-LN106WS',\n",
       " 'Dell G7 7500 15.6inch FHD 300 Hz Display Gaming Laptop (10th Gen i9-10885H / 16 GB / 1TB SSD / NVIDIA RTX 2070 8GB Graphics / 1Yr Premium Warranty / Win 10 + MS Office H&S 2019) D560233WIN9B, Black',\n",
       " '(Renewed) HP Omen 15-dh0139TX Gaming Laptop (9th Gen i9-9880H/16GB/1TB HDD + 512GB SSD/Win 10/8GB NVIDIA RTX 2080 Graphics) & Z3700 Wireless Mouse',\n",
       " 'MSI Gaming Stealth GS66, Intel 12th Gen. i9-12900H, 15.6\" QHD 240Hz Gaming Laptop (16GB*2/1TB NVMe SSD/Windows 11 Home/Nvidia RTX 3070Ti 8GB GDDR 6/ Black/2.1Kg), 12UGS-038IN',\n",
       " 'Dell Precision 5550 || i9 -10885H || 16GB || 1TB NVMe || T2000 4 GB || Win 10 Pro (Free Upgrade Win 11Pro) / 15.6 FHD+ / 3 Year ADP',\n",
       " 'HP ZBook Power G8/ Intel core i9-11900H 8 Core/32GB RAM /1TB NVMe SSD /15.6” FHD /Nvidia Quadro T1200 Graphics 4 GB DDR6 /Windows 10 Pro / 3 Year Warranty']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting title data from the tags\n",
    "for i in title_tagsi9:       # iterating in title_tags\n",
    "    title=i.text           # extracting text from the tags\n",
    "    titlei9.append(title)   # appendingg the text title data into the empty list ttle8\n",
    "titlei9         # printing title data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69eeec3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titlei9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating ratings_tags\n",
    "ratings_tagsi9 = driver.find_elements_by_xpath(\"//a[@href='javascript:void(0)']/i/span\")\n",
    "ratings_tagsi9[0:4]   # printing 4 rating_tags for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dca59d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting ratings data from the tags\n",
    "for i in ratings_tagsi9:\n",
    "    rating=i.text\n",
    "    ratingsi9.append(rating)\n",
    "ratingsi9      # printing rating data  #  not sure why ratings data comes as empty although the code looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9352d4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratingsi9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating price_tags\n",
    "price_tagsi9 = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "price_tagsi9[0:4]   # printing 4 price_tags just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3c43964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,44,990',\n",
       " '1,44,990',\n",
       " '3,31,990',\n",
       " '2,02,990',\n",
       " '3,79,990',\n",
       " '2,32,374',\n",
       " '2,85,390',\n",
       " '2,05,990',\n",
       " '1,38,000',\n",
       " '3,29,990',\n",
       " '2,25,000',\n",
       " '2,50,000']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the price data from the price_tags\n",
    "for i in price_tagsi9:\n",
    "    price=i.text\n",
    "    pricei9.append(price)\n",
    "pricei9      # printing price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "280945f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pricei9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24317f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on \"clear\" so that we can click on \"Intel Core i7\" again\n",
    "clear = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[2]/ul/li[1]/span/a/span[2]\")\n",
    "clear.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3089b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticking filter of \"Intel Core i7\"\n",
    "cpu_filteri7 = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[11]/span/a/div/label/i\")\n",
    "cpu_filteri7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a57cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists to store data\n",
    "titlei7=[]\n",
    "ratingsi7=[]\n",
    "pricei7=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2022eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating title tags\n",
    "title_tagsi7 = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")  \n",
    "title_tagsi7[0:10]       # printing first 10 title tags just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "56221f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acer Predator Helios 300 11th Gen Intel Core i9-11900H 15.6 inches FHD IPS Gaming Laptop (32GB/1TB SSD/Windows 11 Home/8GB Graphics/NVIDIA GeForce RTX 3070/300 Hz, Black, 2.3Kg) PH315-54',\n",
       " 'MSI Katana GF66 Gaming, Intel i7-11800H, 15.6\" FHD IPS-Level 144Hz Panel Laptop (16GB/512GB NVMe SSD/Windows 10 Home/Nvidia RTX3050Ti 4GB GDDR6/Black/2.25Kg), 11UD-476IN',\n",
       " 'Mi Notebook Ultra 3.2K Resolution Display Intel Core i7-11370H 11th Gen 15.6-inch(39.62 cm) Thin and Light Laptop (16GB/512GB SSD/Iris Xe Graphic/Win 10/MS Office 21/Backlit KB/FP Sensor/1.7Kg)',\n",
       " 'ASUS VivoBook 14 (2021), 14-inch (35.56 cms) FHD, Intel Core i7-1065G7 10th Gen, Thin and Light Laptop (16GB/512GB SSD/Integrated Graphics/Office 2021/Windows 11/Silver/1.6 Kg), X415JA-EK701WS',\n",
       " 'Samsung Galaxy Book2 Intel 12th Gen core i7 EvoTM  39.6cm (15.6\") FHD LED Thin & Light Laptop (16 GB/512 GB SSD/Windows 11/MS Office Home & Student 2021/Graphite/1.55Kg), NP750XED-KC2IN',\n",
       " 'HP Pavilion x360 11th Gen Intel Core i7 14 inch(35.6 cm) FHD Multitouch 2-in-1 Laptop(16GB RAM/512GB SSD/B&O/Win 11/FPR/Backlit KB/Intel Iris Xe Graphics/Pen/Alexa/MS Office/Silver/1.52Kg) 14-dy1047TU',\n",
       " 'LG Gram 16 inches Intel Evo 11th Gen Core i7 Ultra-Light Laptop (16 GB RAM, 512 GB SSD, New Windows 11 Home Preload, Iris Xe Graphics, USC -C x 2 (with Power), 1.19 kg, 16Z90P-G.AH85A2, Black)',\n",
       " 'LG Gram Intel Evo 11th Gen Core i7 17 inches Ultra-Light Laptop (16 GB RAM, 512 GB SSD, New Windows 11 Home Preload, Iris Xe Graphics, USC -C x 2 (with Power), 1.35 kg, 17Z90P-G.AH85A2, Black)',\n",
       " 'HP Pavilion 14, 11th Gen Intel Core i7-16GB RAM/1TB SSD 14 inch(35.6 cm) Laptop/Intel Iris Xe Graphics/Backlit Keyboard/Alexa/B&O Audio/Fast Charge/FPR/Win 11/MS Office, 14-dv1029TU,Natural Silver',\n",
       " 'Lenovo ThinkBook 15 Intel 11th Gen Core i7 15.6\"(39.62 cm)FHD Thin and Light Laptop (16GB/512GB SSD/Windows 11 Home/MS Office H&S 2021/Iris® Xe Graphics/Backlit/Mineral Grey/1.7 Kg) 20VE00W4IH']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting title data from the tags\n",
    "for i in title_tagsi7:       # iterating in title_tags\n",
    "    title=i.text           # extracting text from the tags\n",
    "    titlei7.append(title)   # appending the text title data into the empty list\n",
    "titlei7[0:10]         # printing title data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1dabecff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titlei7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating ratings_tags\n",
    "ratings_tagsi7 = driver.find_elements_by_xpath(\"//a[@href='javascript:void(0)']/i/span\")\n",
    "ratings_tagsi7[0:10]   # printing 10 rating_tags for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "02b5e0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting ratings data from the tags\n",
    "for i in ratings_tagsi7:\n",
    "    rating=i.text\n",
    "    ratingsi7.append(rating)\n",
    "ratingsi7[0:10]      # printing 10 rating data  #  not sure why ratings data comes as empty although the code looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d249c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratingsi7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating price_tags\n",
    "price_tagsi7 = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "price_tagsi7[0:10]   # printing 10 price_tags just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee4a15a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,69,990',\n",
       " '91,499',\n",
       " '77,999',\n",
       " '57,490',\n",
       " '79,990',\n",
       " '85,890',\n",
       " '1,01,112',\n",
       " '93,999',\n",
       " '86,990',\n",
       " '86,990']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the price data from the price_tags\n",
    "for i in price_tagsi7:\n",
    "    price=i.text\n",
    "    pricei7.append(price)\n",
    "pricei7[0:10]      # printing 10 price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9f4cb181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pricei7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "28530f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()   # closing the driver at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac2388",
   "metadata": {},
   "source": [
    "# Question 9 Answer --->  python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. Scraping company name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae09b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver       # importing webdriver from selenium for opening automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")    # ignoring warnings that may arise\n",
    "import time                          # time is used to stop the webbrowser for a specified time for the operations to take place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02af7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening automated chrome window\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9770dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the https://www.ambitionbox.com/ in automated chrome window\n",
    "ambitionbox = driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7a16f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on \"Jobs\" as per question\n",
    "jobsoption = driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[6]\")\n",
    "jobsoption.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89de2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In “Search by Designations, Companies, Skills” entering “Data Scientist”\n",
    "designation9 = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "designation9.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8760cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button\n",
    "search_button9 = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span\")\n",
    "search_button9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5e0643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on location drop down to get more options\n",
    "location_dropdown = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i\")\n",
    "location_dropdown.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "385553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering \"Noida\" in the location search tab\n",
    "location_search = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "location_search.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05256334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the Noida tick mark circle\n",
    "location_tickmark = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\")\n",
    "location_tickmark.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9bb8de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists to store data\n",
    "company_name9=[]\n",
    "days_job_posted=[]\n",
    "rating9=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9359b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating company name tags\n",
    "company_name_tags = driver.find_elements_by_xpath(\"//a[@class='title noclick']\")\n",
    "company_name_tags[0:4]      # printing 4 company name tags for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting company name from the tags\n",
    "for i in company_name_tags:\n",
    "    company=i.text\n",
    "    company_name9.append(company)\n",
    "company_name9[0:4]           # printing 4 company names for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating No. of days ago when job was posted tags\n",
    "no_of_days_ago_tags = driver.find_elements_by_xpath(\"//div[@class='other-info']/span[1]\")\n",
    "no_of_days_ago_tags[0:4]      # printing 4 tags for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb65e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting no_of_days_ago from the tags\n",
    "for i in no_of_days_ago_tags:\n",
    "    days=i.text\n",
    "    days_job_posted.append(days)\n",
    "days_job_posted[0:4]           # printing 4 no_of_days_ago for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7864eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating tags of rating of the company\n",
    "rating_of_the_company = driver.find_elements_by_xpath(\"//span[@class='body-small']\")\n",
    "rating_of_the_company[0:4]     # printing 4 tags for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the ratings data from the tags\n",
    "for i in rating_of_the_company:\n",
    "    rating=i.text\n",
    "    rating9.append(rating)\n",
    "rating9[0:4]                   # printing 4 ratings for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcf5ed38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# printing length\n",
    "print(len(company_name9),len(days_job_posted),len(rating9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7a0ca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of days ago posted</th>\n",
       "      <th>Rating of the Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist- AI/ML- R&amp;D</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oracle HCM BI Technical Lead/Manager (People A...</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For Data Scientist + Python/R+ Predicti...</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Immediate Joiners</td>\n",
       "      <td>14d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine Learning (5-14 yrs)</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist- Fresher Opening - Newgen Softw...</td>\n",
       "      <td>20d ago</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst / Data Scientist</td>\n",
       "      <td>29d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name No. of days ago posted  \\\n",
       "0                         Data Scientist- AI/ML- R&D                 7d ago   \n",
       "1                                     Data Scientist                19d ago   \n",
       "2  Oracle HCM BI Technical Lead/Manager (People A...                 5d ago   \n",
       "3  Hiring For Data Scientist + Python/R+ Predicti...               1mon ago   \n",
       "4                 Data Scientist - Immediate Joiners                14d ago   \n",
       "5       Data Scientist - Machine Learning (5-14 yrs)                18d ago   \n",
       "6                                     Data Scientist                 5d ago   \n",
       "7  Data Scientist- Fresher Opening - Newgen Softw...                20d ago   \n",
       "8                      Data Analyst / Data Scientist                29d ago   \n",
       "9                              Senior Data Scientist               1mon ago   \n",
       "\n",
       "  Rating of the Company  \n",
       "0                   3.9  \n",
       "1                   4.0  \n",
       "2                   3.9  \n",
       "3                   4.0  \n",
       "4                   3.8  \n",
       "5                   4.1  \n",
       "6                   3.7  \n",
       "7                   3.5  \n",
       "8                   3.7  \n",
       "9                   4.2  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making data frame for the first 10 jobs results\n",
    "ambitionboxjobs = pd.DataFrame({'Company Name':company_name9,'No. of days ago posted':days_job_posted,'Rating of the Company':rating9})\n",
    "ambitionboxjobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()  # to close the driver at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb194a8",
   "metadata": {},
   "source": [
    "# Question 10 Answer ---> python program to scrape the salary data for Data Scientist designation. Scraping company name, total salary record, average salary, minimum salary, maximum salary, experience required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf1c698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver      # imports webdriver from selenium to open automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")   # ignores warnings that might arise \n",
    "import time                         # used to stop the webbrowser for a few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef1db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open automated chrome window\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb68f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening ambitionbox.com in automated chrome window\n",
    "ambitionboxwindow = driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d37ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on salaries option \n",
    "salariestab = driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[4]\")\n",
    "salariestab.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b088996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputing \"Data scientist\" in \"Search Job Profile\"\n",
    "search_tab = driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "search_tab.send_keys(\"Data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc27497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on \"Data scientist\" dropdown\n",
    "dropdown = driver.find_element_by_xpath(\"//p[@class='tt_text']\")\n",
    "dropdown.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "163210ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists to store data\n",
    "company_name10=[]\n",
    "total_salary_record=[]\n",
    "average_salary=[]\n",
    "minimum_salary=[]\n",
    "maximum_salary=[]\n",
    "experience_required10=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd4a59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there is no mention to scrap the details individually we will use loop method\n",
    "for i in range(0,1):\n",
    "    company_name_tags = driver.find_elements_by_xpath(\"//div[@class='name']/a\")     # locating tags\n",
    "    for i in company_name_tags:\n",
    "        company=i.text                                                              # extracting text from the tags\n",
    "        company_name10.append(company)                                              # appending in empty list\n",
    "    total_salary_record_tags = driver.find_elements_by_xpath(\"//div[@class='name']/span\")       # locating tags\n",
    "    for i in total_salary_record_tags:\n",
    "        total_salary=i.text                                                                     # extracting text from the tags\n",
    "        total_salary_record.append(total_salary)                                                # appending in empty list\n",
    "    average_salary_tags = driver.find_elements_by_xpath(\"//p[@class='averageCtc']\")       # locating tags\n",
    "    for i in average_salary_tags:\n",
    "        avg=i.text                                                                        # extracting text from the tags\n",
    "        average_salary.append(avg)                                                        # appending in empty list\n",
    "    minimum_salary_tags = driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[1]\")        # locating tags\n",
    "    for i in minimum_salary_tags:\n",
    "        minimum=i.text                                                                                 # extracting text from the tags\n",
    "        minimum_salary.append(minimum)                                                                 # appending in empty list\n",
    "    maximum_salary_tags = driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[2]\")        # locating tags\n",
    "    for i in maximum_salary_tags:\n",
    "        maximum=i.text                                                                                 # extracting text from the tags\n",
    "        maximum_salary.append(maximum)                                                                 # appending in empty list\n",
    "    experience_required_tags = driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\")    # locating tags\n",
    "    for i in experience_required_tags:\n",
    "        experience=i.text.replace(\"Data Scientist\\n . \\n\",\"\").replace(\" exp\",\"\")   # extracting text from the tags and replacing unwanted items                    \n",
    "        experience_required10.append(experience)                                   # appending in empty list                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bc1e43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 yrs',\n",
       " '3-4 yrs',\n",
       " '4 yrs',\n",
       " '2 yrs',\n",
       " '3-4 yrs',\n",
       " '2-4 yrs',\n",
       " '2-4 yrs',\n",
       " '2-4 yrs',\n",
       " '4 yrs',\n",
       " '4 yrs']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_required10        # after removing the \"Data Scientist\\n . \\n\" and \" exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f27f93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# printing length\n",
    "print(len(company_name10),len(total_salary_record),len(average_salary),len(minimum_salary),len(maximum_salary),len(experience_required10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "420c2848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Total Salary Record</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 29.7L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>3 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 32 salaries</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 18.9L</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 81 salaries</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 46 salaries</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 53 salaries</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name   Total Salary Record Average Salary  \\\n",
       "0                   Walmart  based on 11 salaries        ₹ 29.7L   \n",
       "1                  Ab Inbev  based on 32 salaries        ₹ 20.5L   \n",
       "2              Reliance Jio  based on 10 salaries        ₹ 18.9L   \n",
       "3                        ZS  based on 15 salaries        ₹ 15.9L   \n",
       "4                     Optum  based on 27 salaries        ₹ 15.2L   \n",
       "5         Fractal Analytics  based on 81 salaries        ₹ 15.2L   \n",
       "6           Tiger Analytics  based on 46 salaries        ₹ 14.8L   \n",
       "7              UnitedHealth  based on 53 salaries        ₹ 14.0L   \n",
       "8                   Verizon  based on 14 salaries        ₹ 12.7L   \n",
       "9  Ganit Business Solutions  based on 13 salaries        ₹ 12.4L   \n",
       "\n",
       "  Minimum Salary Maximum Salary Experience Required  \n",
       "0        ₹ 25.0L        ₹ 35.0L               3 yrs  \n",
       "1        ₹ 15.0L        ₹ 25.5L             3-4 yrs  \n",
       "2         ₹ 5.6L        ₹ 26.2L               4 yrs  \n",
       "3         ₹ 9.8L        ₹ 20.0L               2 yrs  \n",
       "4        ₹ 11.0L        ₹ 22.0L             3-4 yrs  \n",
       "5         ₹ 9.5L        ₹ 22.0L             2-4 yrs  \n",
       "6         ₹ 9.0L        ₹ 20.0L             2-4 yrs  \n",
       "7         ₹ 8.3L        ₹ 20.5L             2-4 yrs  \n",
       "8        ₹ 10.0L        ₹ 21.0L               4 yrs  \n",
       "9         ₹ 8.5L        ₹ 15.0L               4 yrs  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe with all the above extracted data\n",
    "ambitionboxdatascientist = pd.DataFrame({'Company Name':company_name10,'Total Salary Record':total_salary_record,'Average Salary':average_salary,'Minimum Salary':minimum_salary,'Maximum Salary':maximum_salary,'Experience Required':experience_required10})\n",
    "ambitionboxdatascientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e159b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()       # closing the driver at the end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
